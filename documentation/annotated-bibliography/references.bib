%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{engel2014lsd,
    title = {LSD-SLAM: Large-scale direct monocular SLAM},
    author = {Engel, Jakob and Sch{\"o}ps, Thomas and Cremers, Daniel},
    booktitle = {European conference on computer vision},
    pages = {834--849},
    year = {2014},
    organization = {Springer}
}

@inproceedings{engel2015_stereo_lsdslam,
    author = {J. Engel and J. Stueckler and D. Cremers},
    title = {Large-Scale Direct SLAM with Stereo Cameras},
    booktitle = {International Conference on Intelligent Robots and Systems (IROS)},
    year = {2015},
    month = {sept},
    keywords = {slam, stereo, semidense, reconstruction, vslam},
}

@manual{nasa-comp-2021,
    title = {NASA Robotic Mining Competition Lunabotics 2021 Registration, Rules, and Rubrics},
    author = {NASA},
    url = {https://www.nasa.gov/sites/default/files/atoms/files/000_rmc_lunabotics_rules_rubrics_2021.pdf},
    addendum = {This document, given to every Robotic Mining Competition Teams, gives the list of rules, restraints,
    and scoring that will dictate the whole of the Robotic Mining Competition. With NASA as one of our primary
    stakeholders, this document took the roll as a list of their requirements and suggestions as we went through our
    design process. It also provides insight into reasons for why their requirements and point scoring is in place,
    which has give the whole design process more meaning. The main section we were focused on was section 7.5 Mining
    Points - Autonomy. In this section, the document goes in detail on the different points and requirements associated
    with each. The aim for MONKEY was Travel Automation, as the Competition Team would not have the time to complete
    this in a reasonable time, in addition to the actual competition robot. In addition to the requirements listed in
    this section, the rest of the document outlines other requirements that need to be adhered to, in order for our
    final product to be used on the competition robot. They also provided documentation on the mining arena that we
    would compete in, the physical properties of the surface being driven upon, and the points penalties which can be
    associated with different design ideas. This let us compare different solutions in terms of points for the team, as
    well as other factors of consideration.}
}

@book{Lav06,
    author = {S. M. LaValle},
    title = {Planning Algorithms},
    publisher = {Cambridge University Press},
    address = {Cambridge, U.K.},
    note = {Available at http://planning.cs.uiuc.edu/},
    year = {2006},
    addendum = {
    Chapters 2 and 8 of the book Planning Algorithms, authored by Steven M. LaValle and published by Cambridge
    University, discusses methods of modeling and planning motion through both discrete spaces and continuous spaces.
    One approach of particular interest involves modeling a goal position as an attractor and obstacles as repulsors,
    creating a potential field that could guide an agent from any starting location to the goal. The MONKEY would need
    to implement some form of navigation function to carry out its role of guiding the RMC team’s robot to a dig site
    autonomously, so we used the ideas presented in Planning Algorithms as a launch point for brainstorming. The
    potential field method was deemed unsuitable as we needed to model not only the robot’s position but its orientation
    as well, and it had to be possible to specify initial and goal orientations. In the end, we settled on using a
    Markov Decision Process (MDP) as it is more flexible in state-space construction, and while Planning Algorithms does
    not explicitly mention MDPs, it does cover value iteration, a method of solving MDPs, in Chapter 2.
    }
}

@INPROCEEDINGS{5979561,
    author={E. {Olson}},
    booktitle={2011 IEEE International Conference on Robotics and Automation},
    title={AprilTag: A robust and flexible visual fiducial system},
    year={2011},
    pages={3400-3407},
    abstract={While the use of naturally-occurring features is a central focus of machine perception, artificial
    features (fiducials) play an important role in creating controllable experiments, ground truthing, and in
    simplifying the development of systems where perception is not the central objective. We describe a new visual
    fiducial system that uses a 2D bar code style "tag", allowing full 6 DOF localization of features from a single
    image. Our system improves upon previous systems, incorporating a fast and robust line detection system, a stronger
    digital coding system, and greater robustness to occlusion, warping, and lens distortion. While similar in concept
    to the ARTag system, our method is fully open and the algorithms are documented in detail.},
    keywords={Encoding;Visualization;Robustness;Payloads;Detectors;Image segmentation;Robots},
    doi={10.1109/ICRA.2011.5979561},
    ISSN={1050-4729},
    month={May},
    addendum = {This whitepaper, written by Edward Olson of the University of Michigan EECS department, outlines the
    AprilTag system of fiducial markers for computer vision applications. The article talks in-depth about the math
    involved in AprilTag detection, as well as the structure of an AprilTag marker. This article is relevant to the
    project because the M.O.N.K.E.Y. needs to implement some form of visual fiducial detection to aid in locating
    important landmarks in the field, and AprilTag is a robust fiducial system suited for such a task.}
}

@manual{zedmanual,
    title = "Stereolabs Docs: API Reference, Tutorials, and Integration",
    url = "https://www.stereolabs.com/docs/"
}

@online{OpenCV,
    title = {OpenCV: Depth Map from Stereo Images},
    date = {2021-04-11},
    url = {https://docs.opencv.org/master/dd/d53/tutorial_py_depthmap.html}
}

@article{falin2003reverse,
    title={Reverse current/battery protection circuits},
    author={Falin, Jeff and Power, PMP Portable},
    journal={Texas Instruments},
    year={2003}
}

@online{OpenSLAM,
    title = {OpenSLAM},
    date = {2020},
    url = {https://openslam-org.github.io/openratslam.html}
}

@online{ratslam,
    title = {davidmball/ratslam},
    date = {2019},
    url = {https://github.com/davidmball/ratslam}
}

@online{bluetooth,
    title = {Bluetooth Angle Estimation for Real-Time Locationing},
    author = {Sauli Lehtimäki},
    date = {2020},
    url = {https://www.silabs.com/whitepapers/bluetooth-angle-estimation-for-real-time-locationing},
    addendum = {This whitepaper, written by Sauli Lehtimaki, Senior Software Engineer, Silicon Labs, discusses the
    process for real-time localization with Bluetooth. The article goes into detail on how the angle of arrival and
    angle of departure  of the signals in the Bluetooth arrays can be used to achieve localization. It also goes into
    the math and science that allow devices to make these estimations, and different advantages in different array
    configurations. This source is relevant to the MONKEY project in helping to determine whether using Bluetooth is a
    plausible method of achieving localization.Not only does it describe how the location would work from a circuit
    perspective, it also provided challenges that would need to be overcome in order to get the location finder to work.
    While it was possible that a particular Bluetooth development board may have an accompanying SDK (software
    development kit) that would solve these problems, we had to be prepared to figure out how to solve them ourselves.
    Some problems, such as high processing power needed, would be a simple solution, while others, such as antenna
    coupling, would be harder to overcome. It also provided other solutions using bluetooth, in case the antenna array
    method was unsuccessful. While the team ended up not using bluetooth in our final design, this article showed us
    that it was a plausible solution to our localization needs and could be useful to the NASA RMC team in the future.}
}

@article{kim2018introduction,
    title={Introduction to Kalman filter and its applications},
    author={Kim, Youngjoo and Bang, Hyochoong},
    journal={Introduction and Implementations of the Kalman Filter},
    volume={1},
    pages={1--16},
    year={2018},
    publisher={IntechOpen},
    addendum = {
    This excerpt covers the workings of the Kalman filter, and has been instrumental in efforts
    towards sensor fusion by the team.

    Kalman filters are used for estimating states in linear
    dynamical systems, although extensions exist for nonlinear systems. Kalman filters are useful
    for sensor fusion because they can be used to model covariances in different estimates of state
    variables. For example, current velocity is related to future position.

    This text covers the algorithm in sufficient detail for an inexperienced individual to become
    quickly familiar with the technique, and was quite useful in early work at modeling anticipated
    bluetooth localization data with localization data from the stereoscopic vision system.
    },
}

@online{actix,
    title = {Actix Web Documentation},
    url = {https://actix.rs/docs/},
    addendum = {
    Actix-Web is the http server used by the project. Actix-Web is widely considered to be among
    the fastest open-source servers, and it leverages asynchronous multi-worker techniques to
    ensure low overhead.

    The referenced page here contains the documentation on Actix-Web.
    },
}

@online{tokio,
    title = {Tokio Web Site},
    url = {https://tokio.rs/},
    addendum = {
    Tokio is the asynchronous engine powering Actix-Web, and much of our asynchronous backend.
    Tokio leverages work-stealing multi-worker concurrency to ensure efficient performance across
    multiple CPUs, while also performing well on a single CPU. Tokio is very lightweight, and is
    among the fastest such runtimes currently in use.

    The linked page contains the documentation for Tokio.
    },
}